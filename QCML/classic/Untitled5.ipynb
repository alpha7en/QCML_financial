{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPdW2Rh2gHiWqGNZ0QGvjXF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BZkwWQhJdczT","executionInfo":{"status":"ok","timestamp":1745322259219,"user_tz":-180,"elapsed":7065,"user":{"displayName":"Alpha Seven","userId":"14718637863974417302"}},"outputId":"21df7406-d0ee-4b2b-f9be-76abc3faf9ea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting apimoex\n","  Downloading apimoex-1.4.0-py3-none-any.whl.metadata (5.4 kB)\n","Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from apimoex) (2.32.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->apimoex) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->apimoex) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->apimoex) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->apimoex) (2025.1.31)\n","Downloading apimoex-1.4.0-py3-none-any.whl (11 kB)\n","Installing collected packages: apimoex\n","Successfully installed apimoex-1.4.0\n"]}],"source":["pip install apimoex"]},{"cell_type":"code","source":["pip install statsmodels\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fl7bITYgdyRa","executionInfo":{"status":"ok","timestamp":1745322269523,"user_tz":-180,"elapsed":8770,"user":{"displayName":"Alpha Seven","userId":"14718637863974417302"}},"outputId":"8ff1503c-4c26-4eb5-fbb5-441d6af7f6f2"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: statsmodels in /usr/local/lib/python3.11/dist-packages (0.14.4)\n","Requirement already satisfied: numpy<3,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (2.0.2)\n","Requirement already satisfied: scipy!=1.9.2,>=1.8 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (1.14.1)\n","Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (2.2.2)\n","Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (1.0.1)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from statsmodels) (24.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import requests\n","import apimoex\n","import statsmodels.api as sm\n","from datetime import date\n","import time # Для пауз между запросами\n","import os # Для работы с файлами\n","\n","# --- Конфигурация ---\n","START_DATE = '2020-04-17'\n","END_DATE = '2025-04-17'\n","BOARD = 'TQBR' # Основной режим торгов T+2\n","IMOEX_TICKER = 'IMOEX'\n","NEWS_DATA_PATH = 'final_dataset.csv' # Укажите путь к вашему файлу\n","OUTPUT_DATASET_PATH = 'moex_qc_dataset.parquet' # Выходной файл датасета\n","\n","# Признаки из статьи, которые будем нормализовать (включая Beta и Size для очистки)\n","# Short Utilization исключен из-за проблем с данными\n","FEATURES_TO_NORMALIZE = [\n","    'Accruals', 'EBITDA_to_TEV', 'Momentum', 'Operating_Efficiency',\n","    'Profit_Margin', 'Size', 'Value', 'Beta' # Beta и Size для ортогонализации, но тоже нормализуются\n","]\n","\n","# Список всех признаков, включая GICS dummies и новости, для регрессии очистки\n","# Этот список будет формироваться динамически после загрузки всех данных\n","ALL_REGRESSION_FACTORS = FEATURES_TO_NORMALIZE[:] # Копируем нормализуемые\n","# Добавятся GICS dummies (будут иметь префикс 'GICS_') и новости (ваши названия колонок)\n","\n","\n","# --- Инициализация ---\n","session = requests.Session()\n","\n","print(f\"Старт обработки данных для периода: {START_DATE} - {END_DATE}\")\n","\n","# --- Шаг 1: Определение Вселенной Акций MOEX ---\n","print(\"\\nШаг 1: Определение вселенной акций MOEX...\")\n","\n","try:\n","    # Получаем список всех акций в режиме TQBR\n","    # Документация apimoex.get_board_securities: table='securities' (справочник), board='TQBR'\n","    # Добавляем 'SECTYPE' чтобы потом отфильтровать не-акции, если нужно\n","    board_securities_data = apimoex.get_board_securities(\n","        session=session,\n","        table=\"securities\",\n","        board=BOARD,\n","        columns=('SECID', 'SHORTNAME', 'SECTYPE', 'LOTSIZE', 'ISSUESIZE') # ISSUESIZE может помочь для MarketCap, но его историчность под вопросом\n","    )\n","    board_securities_df = pd.DataFrame(board_securities_data)\n","\n","    # Фильтруем только акции ('common stock')\n","    # SEC TYPE 'stocks'\n","    # https://iss.moex.com/iss/reference/32 -> securities -> type\n","    stock_tickers_df = board_securities_df[board_securities_df['SECTYPE'] == '1'].copy()\n","\n","    # Можно добавить дополнительные фильтры:\n","    # 1. Исключить фонды, ETF, и т.д. (уже сделано по 'SECTYPE')\n","    # 2. Фильтр по минимальной капитализации (если есть ISSUESIZE) или объему торгов (нужны исторические данные)\n","    # 3. Фильтр по наличию истории торгов за наш период (сделаем позже при загрузке)\n","    # 4. Фильтр по наличию финансовой отчетности (главная проблема, сделаем позже, отсеивая тикеры без данных)\n","\n","    initial_tickers = stock_tickers_df['SECID'].tolist()\n","    initial_tickers =initial_tickers[:5]\n","    print(f\"Найдено {len(initial_tickers)} потенциальных тикеров в режиме {BOARD}.\")\n","\n","except Exception as e:\n","    print(f\"Ошибка при получении списка тикеров: {e}\")\n","    initial_tickers = [] # Если ошибка, список тикеров будет пустым\n","\n","# --- Шаг 2: Сбор Исходных Данных ---\n","print(\"\\nШаг 2: Сбор исходных рыночных данных...\")\n","\n","all_market_data = []\n","valid_tickers = [] # Список тикеров, для которых удалось загрузить данные\n","\n","# Загрузка данных по IMOEX\n","imoex_data = None\n","try:\n","    print(f\"Загрузка данных для индекса {IMOEX_TICKER}...\")\n","    # get_board_history для индекса, режим 'MRNW' обычно\n","    # https://iss.moex.com/iss/reference/65\n","    # engine='stock', market='index'\n","    imoex_hist = apimoex.get_board_history(\n","        session=session,\n","        security=IMOEX_TICKER,\n","        start=START_DATE,\n","        end=END_DATE,\n","        board='MRNW', # Режим для индексов\n","        market='index',\n","        columns=('TRADEDATE', 'CLOSE', 'VOLUME', 'VALUE') # VOLUME и VALUE для индекса не нужны, но запросим основные\n","    )\n","    imoex_data = pd.DataFrame(imoex_hist)\n","    imoex_data['TRADEDATE'] = pd.to_datetime(imoex_data['TRADEDATE'])\n","    imoex_data.set_index('TRADEDATE', inplace=True)\n","    imoex_data = imoex_data[['CLOSE']].rename(columns={'CLOSE': f'{IMOEX_TICKER}_CLOSE'})\n","    print(f\"Загружены данные для {IMOEX_TICKER} ({len(imoex_data)} дней).\")\n","\n","except Exception as e:\n","    print(f\"Ошибка при загрузке данных для {IMOEX_TICKER}: {e}\")\n","    imoex_data = None # Если ошибка, данные IMOEX будут None\n","\n","# Загрузка данных по акциям\n","# Пауза для соблюдения лимитов API\n","PAUSE_DURATION = 0.1 # секунды\n","\n","for i, ticker in enumerate(initial_tickers):\n","    print(f\"Загрузка данных для {ticker} ({i+1}/{len(initial_tickers)})...\")\n","    try:\n","        # get_board_history для акций, режим TQBR\n","        # https://iss.moex.com/iss/reference/65\n","        # engine='stock', market='shares', board='TQBR'\n","        stock_hist = apimoex.get_board_history(\n","            session=session,\n","            security=ticker,\n","            start=START_DATE,\n","            end=END_DATE,\n","            board=BOARD,\n","            columns=('TRADEDATE', 'CLOSE', 'VOLUME', 'VALUE')\n","        )\n","        stock_df = pd.DataFrame(stock_hist)\n","\n","        if not stock_df.empty:\n","            stock_df['TRADEDATE'] = pd.to_datetime(stock_df['TRADEDATE'])\n","            stock_df['SECID'] = ticker\n","            # Добавляем MarketCap - PLACEHOLDER.\n","            # Нужно получить ISSUESIZE для SECID на каждую дату и умножить на CLOSE.\n","            # ISSUESIZE меняется со временем (допэмиссии и т.д.), его историю сложно получить общедоступно.\n","            # Для примера, добавим пустую колонку MarketCap, которую нужно заполнить из другого источника.\n","            # Либо, если ISSUESIZE не меняется, можно попробовать получить его статически.\n","            # Для целей демонстрации, пока оставим ее пустой или заполним NaN.\n","            # https://iss.moex.com/iss/history/engines/stock/markets/shares/boards/TQBR/securities/SBER.json?iss.meta=off&iss.only=history&history.columns=TRADEDATE,ISSUESIZE\n","            # ISSUE SIZE доступен в истории, но это отдельный запрос для каждой бумаги!\n","            # Это сильно усложнит загрузку данных.\n","            # Временно добавим пустую колонку MarketCap:\n","            stock_df['MarketCap'] = np.nan # Эту колонку нужно заполнить реальными данными\n","\n","            all_market_data.append(stock_df)\n","            valid_tickers.append(ticker)\n","            print(f\"  Успешно загружено {len(stock_df)} строк.\")\n","        else:\n","            print(f\"  Нет данных для {ticker} в указанный период или режиме {BOARD}.\")\n","\n","    except Exception as e:\n","        print(f\"  Ошибка при загрузке данных для {ticker}: {e}\")\n","\n","    time.sleep(PAUSE_DURATION) # Пауза между запросами\n","\n","if not all_market_data:\n","    print(\"\\nОшибка: Не удалось загрузить данные ни для одной акции. Проверьте тикеры, даты и доступность API.\")\n","    exit() # Прерываем выполнение, если нет данных\n","\n","# Объединяем все данные по акциям\n","market_data_df = pd.concat(all_market_data, ignore_index=True)\n","market_data_df.set_index(['TRADEDATE', 'SECID'], inplace=True)\n","market_data_df.sort_index(inplace=True)\n","\n","print(f\"\\nЗагружены данные для {len(valid_tickers)} акций. Общее количество строк: {len(market_data_df)}.\")\n","print(\"Пример загруженных данных:\")\n","print(market_data_df.head())\n","print(market_data_df.tail())\n","\n","# Объединяем с данными IMOEX\n","if imoex_data is not None and not imoex_data.empty:\n","    # Присоединяем IMOEX CLOSE к каждой строке по дате\n","    market_data_df = market_data_df.join(imoex_data, on='TRADEDATE')\n","    print(f\"\\nРазмер DataFrame после присоединения IMOEX: {market_data_df.shape}\")\n","else:\n","    print(\"\\nДанные IMOEX не загружены или пусты. Beta не может быть рассчитана.\")\n","    # Если IMOEX нет, нужно будет исключить Beta из FEATURES_TO_NORMALIZE и ALL_REGRESSION_FACTORS\n","\n","# --- PLACEHOLDER: Загрузка Финансовой Отчетности ---\n","print(\"\\nPLACEHOLDER: Загрузка и обработка финансовой отчетности...\")\n","# Этот шаг требует данных из внешнего источника.\n","# Предположим, что у вас есть DataFrame `financial_data_df`\n","# с колонками: 'TRADEDATE' (дата окончания квартала или дата публикации), 'SECID', 'TOTALASSETS', 'WORKINGCAPITAL', ...\n","# Нужно реализовать логику, которая для каждой ежедневной даты в `market_data_df`\n","# находит последние доступные данные из `financial_data_df`.\n","\n","# Пример создания пустого DataFrame для фин. данных\n","financial_data_df = pd.DataFrame(columns=[\n","    'TRADEDATE', 'SECID', 'TOTALASSETS', 'WORKINGCAPITAL', 'TOTALLIABILITIES',\n","    'LONGTERMINVESTMENTS', 'LONGTERMDEBT', 'REVENUES', 'NETINCOME', 'EBITDA',\n","    'CASHEQUIVALENTS' # Для TEV\n","])\n","# financial_data_df['TRADEDATE'] = pd.to_datetime(financial_data_df['TRADEDATE'])\n","# financial_data_df.set_index(['TRADEDATE', 'SECID'], inplace=True)\n","# Пример: Загрузка из файла CSV (если у вас есть такой файл)\n","# try:\n","#     financial_data_df = pd.read_csv('your_financial_data.csv')\n","#     financial_data_df['TRADEDATE'] = pd.to_datetime(financial_data_df['TRADEDATE'])\n","#     financial_data_df.set_index(['TRADEDATE', 'SECID'], inplace=True)\n","#     print(f\"Загружены финансовые данные. Строк: {len(financial_data_df)}\")\n","# except FileNotFoundError:\n","#     print(\"Файл 'your_financial_data.csv' не найден. Финансовые признаки будут NaN.\")\n","# except Exception as e:\n","#      print(f\"Ошибка при загрузке финансового файла: {e}. Финансовые признаки будут NaN.\")\n","\n","# Логика для присоединения последних доступных фин. данных к ежедневным рыночным данным:\n","# Это сложный merge. Нужно для каждой строки (date, ticker) в market_data_df\n","# найти ближайшую по дате назад запись в financial_data_df для того же тикера.\n","# Можно использовать `pd.merge_asof`. Но financial_data_df должна быть отсортирована по дате.\n","# merged_df = pd.merge_asof(\n","#     market_data_df.reset_index().sort_values('TRADEDATE'), # Отсортировать по дате\n","#     financial_data_df.reset_index().sort_values('TRADEDATE'), # Отсортировать по дате\n","#     on='TRADEDATE',\n","#     by='SECID',\n","#     allowexact=True, # Разрешить совпадение дат (если день публикации совпадает с торговым днем)\n","#     direction='backward' # Искать назад от торговой даты\n","# )\n","# merged_df.set_index(['TRADEDATE', 'SECID'], inplace=True)\n","# market_data_df = merged_df # Обновляем основной DataFrame\n","\n","print(\"ПРИМЕЧАНИЕ: Финансовые данные не загружены. Признаки, зависящие от них, будут NaN.\")\n","# Продолжим, предполагая, что financial_data_df будет интегрирован позже или данные будут NaN.\n","# Если финансовые данные критически важны и недоступны, дальнейшие шаги по расчету признаков\n","# (Accruals, EBITDA_to_TEV, Operating_Efficiency, Profit_Margin, Value) приведут к NaN.\n","\n","# --- PLACEHOLDER: Загрузка Секторальной Классификации (GICS аналог) ---\n","print(\"\\nPLACEHOLDER: Загрузка секторальной классификации...\")\n","# Нужно получить сектор для каждого SECID. apimoex может предоставлять эту инфрмацию\n","# например, через get_board_securities или find_security_description, но не всегда в чистом виде GICS\n","# и не факт, что исторически.\n","# Для примера, добавим пустую колонку 'Sector'\n","market_data_df['Sector'] = 'Unknown' # Эту колонку нужно заполнить реальными данными\n","# Пример: Загрузка из файла CSV (если у вас есть такой файл)\n","# try:\n","#     sector_map_df = pd.read_csv('your_sector_mapping.csv') # columns: 'SECID', 'Sector'\n","#     sector_map_df.set_index('SECID', inplace=True)\n","#     market_data_df = market_data_df.join(sector_map_df, on='SECID', rsuffix='_from_map')\n","#     market_data_df['Sector'] = market_data_df['Sector_from_map'].fillna(market_data_df['Sector'])\n","#     market_data_df.drop(columns='Sector_from_map', inplace=True)\n","#     print(\"Загружена и присоединена секторальная классификация.\")\n","# except FileNotFoundError:\n","#     print(\"Файл 'your_sector_mapping.csv' не найден. Сектора будут 'Unknown'.\")\n","# except Exception as e:\n","#      print(f\"Ошибка при загрузке секторального файла: {e}. Сектора будут 'Unknown'.\")\n","\n","print(\"ПРИМЕЧАНИЕ: Секторальная классификация не загружена. Будет использоваться 'Unknown'.\")\n","\n","# --- Загрузка Глобальных Новостных Признаков ---\n","print(f\"\\nЗагрузка глобальных новостных признаков из {NEWS_DATA_PATH}...\")\n","try:\n","    news_df = pd.read_csv(NEWS_DATA_PATH)\n","    news_df['date'] = pd.to_datetime(news_df['date'])\n","    news_df.rename(columns={'date': 'TRADEDATE'}, inplace=True)\n","    news_df.set_index('TRADEDATE', inplace=True)\n","\n","    # Сохраним названия новостных колонок для использования в регрессии\n","    NEWS_FEATURES = news_df.columns.tolist()\n","    print(f\"Загружены новостные признаки: {NEWS_FEATURES}\")\n","    print(f\"Пример новостных данных:\\n{news_df.head()}\")\n","\n","    # Объединяем новостные данные с основными по дате\n","    # Используем `left_join` чтобы сохранить все торговые дни из market_data_df\n","    market_data_df = market_data_df.join(news_df, on='TRADEDATE')\n","    print(f\"Размер DataFrame после присоединения новостных признаков: {market_data_df.shape}\")\n","\n","except FileNotFoundError:\n","    print(f\"Ошибка: Файл с новостными признаками '{NEWS_DATA_PATH}' не найден.\")\n","    NEWS_FEATURES = [] # Список новостных признаков пуст\n","except Exception as e:\n","    print(f\"Ошибка при загрузке или обработке новостных признаков: {e}\")\n","    NEWS_FEATURES = [] # Список новостных признаков пуст\n","\n","if not NEWS_FEATURES:\n","    print(\"ПРИМЕЧАНИЕ: Новостные признаки не будут включены в регрессию очистки.\")\n","else:\n","     ALL_REGRESSION_FACTORS.extend(NEWS_FEATURES) # Добавляем новостные признаки в список регрессоров\n","\n","# Добавляем GICS dummies в список регрессоров (будут сформированы позже)\n","# ALL_REGRESSION_FACTORS будет окончательно сформирован после создания GICS dummies\n","\n","# --- Промежуточный результат Шага 2 ---\n","print(\"\\nПромежуточный результат после Шага 2:\")\n","print(market_data_df.info())\n","print(market_data_df.head())\n","\n","# Сохраняем промежуточный результат на случай сбоя\n","market_data_df.to_parquet('intermediate_market_data.parquet')\n","print(\"\\nПромежуточные рыночные данные сохранены в 'intermediate_market_data.parquet'.\")\n","\n","# На этом этапе у нас есть market_data_df с ежедневными ценами, объемами, IMOEX,\n","# пустыми колонками для MarketCap и фин.данных (или заполненными NaN),\n","# колонкой для Sector (возможно, 'Unknown'), и присоединенными новостными признаками."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"37rQkrz-d40o","executionInfo":{"status":"ok","timestamp":1745322478919,"user_tz":-180,"elapsed":7768,"user":{"displayName":"Alpha Seven","userId":"14718637863974417302"}},"outputId":"54c55f00-2096-45b8-cebb-64a83e38b507"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Старт обработки данных для периода: 2020-04-17 - 2025-04-17\n","\n","Шаг 1: Определение вселенной акций MOEX...\n","Найдено 5 потенциальных тикеров в режиме TQBR.\n","\n","Шаг 2: Сбор исходных рыночных данных...\n","Загрузка данных для индекса IMOEX...\n","Ошибка при загрузке данных для IMOEX: 'TRADEDATE'\n","Загрузка данных для ABIO (1/5)...\n","  Успешно загружено 426 строк.\n","Загрузка данных для ABRD (2/5)...\n","  Успешно загружено 1269 строк.\n","Загрузка данных для AFKS (3/5)...\n","  Успешно загружено 1269 строк.\n","Загрузка данных для AFLT (4/5)...\n","  Успешно загружено 1269 строк.\n","Загрузка данных для AKRN (5/5)...\n","  Успешно загружено 1269 строк.\n","\n","Загружены данные для 5 акций. Общее количество строк: 5502.\n","Пример загруженных данных:\n","                     CLOSE    VOLUME         VALUE  MarketCap\n","TRADEDATE  SECID                                             \n","2020-04-17 ABRD    134.000      1170  1.567750e+05        NaN\n","           AFKS     13.327  24730800  3.278650e+08        NaN\n","           AFLT     74.200  17887210  1.320893e+09        NaN\n","           AKRN   5762.000      4645  2.676434e+07        NaN\n","2020-04-20 ABRD    135.000      4150  5.576300e+05        NaN\n","                     CLOSE     VOLUME         VALUE  MarketCap\n","TRADEDATE  SECID                                              \n","2025-04-17 ABIO      84.70     596630  5.074025e+07        NaN\n","           ABRD     186.80      29110  5.440600e+06        NaN\n","           AFKS      15.41  149089600  2.252838e+09        NaN\n","           AFLT      71.15   19219930  1.345192e+09        NaN\n","           AKRN   16400.00       1028  1.675864e+07        NaN\n","\n","Данные IMOEX не загружены или пусты. Beta не может быть рассчитана.\n","\n","PLACEHOLDER: Загрузка и обработка финансовой отчетности...\n","ПРИМЕЧАНИЕ: Финансовые данные не загружены. Признаки, зависящие от них, будут NaN.\n","\n","PLACEHOLDER: Загрузка секторальной классификации...\n","ПРИМЕЧАНИЕ: Секторальная классификация не загружена. Будет использоваться 'Unknown'.\n","\n","Загрузка глобальных новостных признаков из final_dataset.csv...\n","Ошибка: Файл с новостными признаками 'final_dataset.csv' не найден.\n","ПРИМЕЧАНИЕ: Новостные признаки не будут включены в регрессию очистки.\n","\n","Промежуточный результат после Шага 2:\n","<class 'pandas.core.frame.DataFrame'>\n","MultiIndex: 5502 entries, (Timestamp('2020-04-17 00:00:00'), 'ABRD') to (Timestamp('2025-04-17 00:00:00'), 'AKRN')\n","Data columns (total 5 columns):\n"," #   Column     Non-Null Count  Dtype  \n","---  ------     --------------  -----  \n"," 0   CLOSE      5426 non-null   float64\n"," 1   VOLUME     5502 non-null   int64  \n"," 2   VALUE      5502 non-null   float64\n"," 3   MarketCap  0 non-null      float64\n"," 4   Sector     5502 non-null   object \n","dtypes: float64(3), int64(1), object(1)\n","memory usage: 273.6+ KB\n","None\n","                     CLOSE    VOLUME         VALUE  MarketCap   Sector\n","TRADEDATE  SECID                                                      \n","2020-04-17 ABRD    134.000      1170  1.567750e+05        NaN  Unknown\n","           AFKS     13.327  24730800  3.278650e+08        NaN  Unknown\n","           AFLT     74.200  17887210  1.320893e+09        NaN  Unknown\n","           AKRN   5762.000      4645  2.676434e+07        NaN  Unknown\n","2020-04-20 ABRD    135.000      4150  5.576300e+05        NaN  Unknown\n","\n","Промежуточные рыночные данные сохранены в 'intermediate_market_data.parquet'.\n"]}]}]}